                                                    ||  Tquant  ||
                                  
| Day 1 
    - R programming 
        - Run R in terminal using "source('filename.r')
        - c(): concatenated character vector function 
        - A <- matrix(1:x, nrow= rows, ncol = cols, byrow = ) 
        - Factors: categorical variables (low, inter, high) 
        - list() 
        - Data frames: DS that contain vectors and factors (same len) 
        - Indexing works like Python with the exception of logical indices 
            - Logical indeices returns a logical vector 
            - weight[weight > 60] 
        - order(): Sorting function  
        - aggregate() 

| Day 2 
    - Copulas  
        - Probability distrbution vs pdfs vs cdfs vs multivariate distrbution vs marginal distrbution 
        - Lebesgue-Stieltjes integral: Integrating prob. distrs.  
            - Different way of writing the integral for the expected value E[x] 
        - Copula: A function that joins a multivariate distribution functions to its 1-D margins 
        - Used to describe the dependence between random variables  
        - Parameters to copula function -> probability distrbutions  
        - An n-copula is an n-variate distrbution function on [0,1]^n with univariate margins 
            uniformly distributed in [0,1] 
        - Proving a function is a copula  
            - Find a suitable probablistic model whose distrbution functions concentrated 
                on [0,1]^n and has uniform marginals  
        - Allow for study of the structure of stochastic dependency in a scale free manner, 
            independent of the specific marginal distrbution, i.e. seperation of dependency  
            structure from the specific marginals  
        - If all univariate margins are continuous, then the copula is unique  
        - Sklar's Theorem 
            - Generate a pair of observations (u, v) from two distrbution functions 
                (U, V) which copula is C. Using an inverse distrbution function, it is 
                possible to extrapolate their joint distrbution function. 
    - Statistical Learning 
        - An Introduction to Statistical Learning (Book, free down. avail.) 
        - Statistical Learning is mostly supervised learning 
            - Regression Problem
                - Y is quantitative
            - Classification Problem
                - Y takes values in a finite unordered set 
        - Unsupervised Learning
            - Not outcome variable 
            - Alg. tries to find a pattern within a dataset 
        - Pretty much ML 
        - Parametric and Structured Models 
            - Linear Models 
                - We estimate the parameters by fitting the model to training data 
                - Almost never correct, but serves as a good approx. of the uknown 
                    true fucntion f(x)
                - Quadratic models tend to be slightly better 
            - Overfitting
                - When the fitted model makes no errors on the training data  
                - Model would not be able to make valid predictions on test data 
                    - Due to having no error 
                - Works well for training but not for test 
            - Assesing model accuracy 
                - Compute Mean Square Error in Training and Test sets 
                    - Compare 
            - Flexibility -> Number of Parameters (kinda)
            - Typically as the flexibility of f increases, variance increases and 
                its bias decreases
            - *Bias *Variance 
            - *Bayes Classifier
            - K-Means clustering (KNN - K Nearest Neighbour)
                - Low K could have higher risk of overfitting 
                - High K could have a higher risk of underfitting 

| Day 3
    - Ising Model
        - Binary scored variables as a function of main and interaction effects 
        - Model of ferromagnetism
        - Used in psychology for network modelling and psychometrics 
        - (sigma) -> set of discrete variables 
            - Magnetic dipole moments of atomic spins 
                -(sigma1): atom i spins upward, +1
                -(sigma2): atom i spins downward -1
            - Spins can be used to determine the energy of a system 
                - Use the Hamiltonian function to calc. energy for (sigma)
        - The dimensionality of a model refers to the number of neighbours each 
            spin is connected too
            - When d <= 2 an exact solution exists 
                - Free energy  
                - Spin-Spin correlation  
            - When d > 2, this is no longer the case 
                - Approximate it with a mean field 
        - The Ising model can be used to model the joint distrbution of binary variables 
            as a function of main effects and pairwise interactions
        - The Psychological Ising model 
            - Question: How do we explain the associations between observed variables 
                - Common cause framework 
            - Latent variable models => a common cause explanation 
            - Statistical model -> Basically data reduction 
            - Theoretical models -> Data-generating mechanism 
            - Network models => mutualistic realtions between the observable variables
            - IRT (Item Response Theory)
                - Models associations between categorical observed variables as a function of a 
                    continuous latent variable
            - Latent variable models and network models are mathematically equivalent 
                - Model fit does thus not say anything about the validity of the 
                    underlying mechanism 
            - Simulation and Estimation
                - For small systems simulatin states is easy as we can calculate the prob. 
                    distrbution for the entire system 
                - When the system grows, the number of possible configurations grows and so 
                    does the time to calculate the probs. 
    - Statistical Learning
        - In the case of a binary outcome, linear regression would not work 
            - However, a logistic regression would work 
        - *logit 
        - Logistic Regression with more than two classes 
            - There will be a linear function for each class 
            - Multi-class logistical regression
        - Discriminant Analysis 
            - Model the distrbution of X in each of the classes individually and 
                use Bayes theorem to obtain the conditional probabilities for the rest 
            - Provides a low dimensional view of the data 
            - More stable when n is small and the distrbution of x is normal
                - In comparison to LR 
        